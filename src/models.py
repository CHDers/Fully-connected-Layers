'''
ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€: 
Descripttion: Yanjun Haoçš„ä»£ç 
version: 1.0.0
Author: Yanjun Hao
Date: 2023-04-02 10:16:10
LastEditors: Yanjun Hao
LastEditTime: 2023-04-02 23:34:08
'''
import pandas as pd
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split
import json
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from rich import print

import matplotlib

font = {'family': 'Times New Roman', 'size': '14'}  # SimSunå®‹ä½“ 'weight':'bold',
matplotlib.rc('font', **font)

from pathlib import Path
import sys

FILE = Path(__file__).resolve()
ROOT_0 = FILE.parents[0]  # project root directory
ROOT_1 = FILE.parents[1]  # project root directory
if str(ROOT_0) not in sys.path:
    sys.path.append(str(ROOT_0))  # add ROOT to PATH
if str(ROOT_1) not in sys.path:
    sys.path.append(str(ROOT_1))  # add ROOT to PATH
from src.Config import ModelConfig


# å®šä¹‰è‡ªå®šä¹‰æ•°æ®é›†ç±»
class CustomDataset(Dataset):
    def __init__(self, data):
        self.data = data

    def __getitem__(self, index):
        x = torch.Tensor(self.data[index][0])
        y = torch.Tensor([self.data[index][1]])
        return x, y

    def __len__(self):
        return len(self.data)


# å®šä¹‰å…¨è¿æ¥ç¥ç»ç½‘ç»œæ¨¡å‹
class Net(nn.Module):
    def __init__(self, input_size, output_size, node_size=(2024, 1024, 512, 128)):
        super().__init__()
        self.fc1 = nn.Linear(input_size, node_size[0])
        self.fc2 = nn.Linear(node_size[0], node_size[1])
        self.fc3 = nn.Linear(node_size[1], node_size[2])
        self.fc4 = nn.Linear(node_size[2], node_size[3])

        self.fc5 = nn.Linear(node_size[3], output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = torch.relu(self.fc4(x))
        x = self.fc5(x)
        return x


# å®šä¹‰è®­ç»ƒå‡½æ•°
def train(model, optimizer, criterion, train_loader, device):
    model.train()
    train_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)
    return train_loss / len(train_loader.dataset)


# å®šä¹‰éªŒè¯å‡½æ•°
def evaluate(model, criterion, val_loader, device):
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
    return val_loss / len(val_loader.dataset)


def load_model_to_predict(model_path: str, input_val_data: object, features_num: int = 4) -> None:
    """
    åŠ è½½æœ€ä¼˜æ¨¡å‹è¿›è¡Œé¢„æµ‹
    :param features_num: æ¨¡å‹çš„è¾“å…¥ç‰¹å¾æ•°
    :param model_path: æœ€ä¼˜æ¨¡å‹è·¯å¾„
    :param input_val_data: é¢„æµ‹æ•°æ®(æœ‰æ ‡ç­¾)
    :return:
    """
    device = ModelConfig.DEVICE
    # åŠ è½½è·¯å¾„ä¸º'model.pth'çš„æ¨¡å‹
    model_state_dict = torch.load(model_path)

    # åˆ›å»ºæ–°çš„ç¥ç»ç½‘ç»œæ¨¡å‹
    model = Net(int(features_num), 1).to(device)

    # ç”¨åŠ è½½çš„æ¨¡å‹çŠ¶æ€å­—å…¸æ›´æ–°æ¨¡å‹å‚æ•°
    model.load_state_dict(model_state_dict)

    # è¿›è¡Œé¢„æµ‹
    val_dataset = CustomDataset(input_val_data)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    model.eval()
    real_value_list, pred_value_list = [], []
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            predict_value = model(inputs)
            real_value_list += [item for sublist in labels.cpu().tolist() for item in sublist]
            pred_value_list += [item for sublist in predict_value.cpu().tolist() for item in sublist]

    # ç»˜å›¾
    plt.figure(figsize=(10, 6))
    plt.plot(real_value_list[:300], label='real')
    plt.plot(pred_value_list[:300], label='predict')
    plt.legend()
    plt.savefig("../run/figure/predict.svg", bbox_inches='tight')
    plt.show()

    # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
    with open('../run/result/predict_result.json', 'w') as f:
        f.write(json.dumps({"real_value": real_value_list, "pred_value": pred_value_list}))


def predict_single_value(model_path: str, val_data=torch.Tensor(1, 4)) -> None:
    """
    åªé¢„æµ‹å€¼ï¼Œä¸è¿›è¡ŒéªŒè¯
    :param model_path: æ¨¡å‹æœ¬åœ°è·¯å¾„
    :param val_data: éœ€è¦é¢„æµ‹çš„è‡ªå˜é‡å€¼(æ— æ ‡ç­¾)
    :return:
    """
    device = ModelConfig.DEVICE
    # åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹
    model = Net(4, 1).to(device)
    model_state_dict = torch.load(model_path)
    model.load_state_dict(model_state_dict)

    model.eval()
    with torch.no_grad():
        # NOTE: é¢„æµ‹å•ä¸ªå€¼
        pred_value = [item for sublist in model(val_data.to(device)).cpu().tolist() for item in sublist]

    # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
    with open('../run/predict_value.json', 'w') as f:
        f.write(json.dumps({"pred_value": pred_value}))


def select_line_to_predict(model_path: str, input_val_data: object, features_num: int = 4):
    """
    åŠ è½½æœ€ä¼˜æ¨¡å‹è¿›è¡Œé¢„æµ‹
    :param features_num: æ¨¡å‹çš„è¾“å…¥ç‰¹å¾æ•°
    :param model_path: æœ€ä¼˜æ¨¡å‹è·¯å¾„
    :param input_val_data: é¢„æµ‹æ•°æ®(æœ‰æ ‡ç­¾)
    :return:
    """
    device = ModelConfig.DEVICE
    # åŠ è½½è·¯å¾„ä¸º'model.pth'çš„æ¨¡å‹
    model_state_dict = torch.load(model_path)

    # åˆ›å»ºæ–°çš„ç¥ç»ç½‘ç»œæ¨¡å‹
    model = Net(int(features_num), 1).to(device)

    # ç”¨åŠ è½½çš„æ¨¡å‹çŠ¶æ€å­—å…¸æ›´æ–°æ¨¡å‹å‚æ•°
    model.load_state_dict(model_state_dict)

    # è¿›è¡Œé¢„æµ‹
    val_dataset = CustomDataset(input_val_data)
    val_loader = DataLoader(val_dataset, batch_size=ModelConfig.BATCH_SIZE, shuffle=False)

    model.eval()
    real_value_list, pred_value_list = [], []
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            predict_value = model(inputs)
            real_value_list += [item for sublist in labels.cpu().tolist() for item in sublist]
            pred_value_list += [item for sublist in predict_value.cpu().tolist() for item in sublist]

    # ç»˜å›¾
    plt.figure(figsize=(10, 6))
    plt.plot(real_value_list[:300], label='real')
    plt.plot(pred_value_list[:300], label='predict')
    plt.legend()
    plt.savefig("../run/figure/predict.svg", bbox_inches='tight')
    plt.show()

    # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
    with open('../run/result/predict_result.json', 'w') as f:
        f.write(json.dumps({"real_value": real_value_list, "pred_value": pred_value_list}))


# å®šä¹‰ä¸»å‡½æ•°
def main(epochs: int = 300, file_path: str = None) -> None:
    # è®¾å®šéšæœºç§å­å’Œè®¾å¤‡
    torch.manual_seed(123)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ„é€ æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    origin_df = pd.read_excel(file_path, index_col=None)
    # å½’ä¸€åŒ–
    # å°†éœ€è¦å½’ä¸€åŒ–çš„åˆ—é€‰æ‹©å‡ºæ¥
    cols_to_norm = ['x_point', 'Temperature', 'Enthalpy value', 'time']

    # å¯¹éœ€è¦å½’ä¸€åŒ–çš„åˆ—è¿›è¡Œå½’ä¸€åŒ–
    scaler = MinMaxScaler()
    origin_df[cols_to_norm] = scaler.fit_transform(origin_df[cols_to_norm])

    # åˆ’åˆ†æ•°æ®é›†
    # å°†DataFrameä¸­çš„xå’Œyè½¬æ¢ä¸ºåˆ—è¡¨
    x = origin_df[cols_to_norm].values.tolist()
    y = origin_df['actual'].values.tolist()
    # å°†xå’Œyå¯¹åº”çš„æ•°æ®æ‰“åŒ…æˆå…ƒç»„
    data = list(zip(x, y))
    train_data, val_data = random_split(data, [int(len(data) * 0.8), int(len(data) * 0.2)])

    # data = [(torch.randn(4), torch.randn(1)) for i in range(1000)]
    # train_data, val_data = random_split(data, [800, 200])
    train_dataset = CustomDataset(train_data)
    val_dataset = CustomDataset(val_data)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # æ„é€ æ¨¡å‹å’ŒæŸå¤±å‡½æ•°
    model = Net(4, 1).to(device)
    criterion = nn.MSELoss()

    # æ„é€ ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # å¼€å§‹è®­ç»ƒæ¨¡å‹
    train_loss_list = []
    val_loss_list = []
    best_val_loss = float('inf')
    for epoch in range(epochs):
        train_loss = train(model, optimizer, criterion, train_loader, device)
        train_loss_list.append(train_loss)
        val_loss = evaluate(model, criterion, val_loader, device)
        val_loss_list.append(val_loss)
        if val_loss < best_val_loss:
            torch.save(model.state_dict(), "../run/best_model.pth")
        if epoch % 10 == 0:
            print(epoch, ':', train_loss)

    # ç»˜å›¾
    plt.figure(figsize=(10, 6))
    plt.plot(train_loss_list, label='train_loss')
    plt.plot(val_loss_list, label='val_loss')
    plt.legend()
    plt.savefig("../run/loss.svg", bbox_inches='tight')
    plt.show()

    # ä¿å­˜lossåˆ°æœ¬åœ°
    with open('../run/loss.json', 'w') as f:
        f.write(json.dumps({"train_loss": train_loss_list, "val_loss": val_loss_list}))

    print("------------å¼€å§‹é¢„æµ‹---------------")
    load_model_to_predict(model_path="../run/best_model.pth", input_val_data=val_data)


if __name__ == '__main__':
    EPOCH = 100
    FILEPATH = "../data/ra.xlsx"
    main(epochs=EPOCH, file_path=FILEPATH)

    # SECTION: å•å€¼é¢„æµ‹
    predict_single_value(model_path="../run/best_model.pth", val_data=torch.Tensor(1, 4))
